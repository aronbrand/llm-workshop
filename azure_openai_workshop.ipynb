{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Workshop Notebook - Azure OpenAI Version\n",
    "\n",
    "**Author:** Aron Brand\n",
    "\n",
    "**Copyright (c) 2024**\n",
    "\n",
    "This notebook is an integral part of Aron Brand's LLM Workshop, designed to explore and utilize the capabilities of large language models (LLMs).\n",
    "\n",
    "**License:**\n",
    "\n",
    "This program is free software: you are encouraged to redistribute and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation. This software is provided under either version 3 of the License, or (at your discretion) any later version.\n",
    "\n",
    "The program is distributed in the hope that it will be useful and informative. However, it comes with no warranty; not even the implied warranty of merchantability or fitness for a particular purpose. For more details, please refer to the GNU General Public License.\n",
    "\n",
    "For a copy of the GNU General Public License, please visit [https://www.gnu.org/licenses/](https://www.gnu.org/licenses/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (1.10.0)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (0.1.3)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (0.0.3)\n",
      "Requirement already satisfied: unstructured in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (0.5.4)\n",
      "Requirement already satisfied: chromadb in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (0.4.22)\n",
      "Requirement already satisfied: langchainhub in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (0.1.14)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (0.23.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (1.10.14)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.14 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (0.1.15)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (0.0.83)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (0.0.15)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain-openai) (0.5.2)\n",
      "Requirement already satisfied: python-magic in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: python-pptx in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (0.6.21)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (1.5.3)\n",
      "Requirement already satisfied: pypandoc in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (1.11)\n",
      "Requirement already satisfied: markdown in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (3.4.1)\n",
      "Requirement already satisfied: python-docx in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (0.8.11)\n",
      "Requirement already satisfied: argilla in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (1.4.0)\n",
      "Requirement already satisfied: openpyxl in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (3.1.2)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (9.2.0)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (4.9.2)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (2022.12.7)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.109.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (3.3.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.60.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.43b0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (7.6.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (3.4.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (5.9.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.16.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.0.3)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchainhub) (2.31.0.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (6.11.0)\n",
      "Requirement already satisfied: packaging>=19.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from fastapi>=0.95.2->chromadb) (0.35.1)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.5.0)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.16.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.11.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.5.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.11)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (1.10.1)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.2)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.13)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.22.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.43b0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.43b0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.43b0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (59.5.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2022.8.17)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (8.1.3)\n",
      "Requirement already satisfied: types-urllib3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from types-requests<3.0.0.0,>=2.31.0.2->langchainhub) (1.26.25.14)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (10.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.18.1)\n",
      "Requirement already satisfied: rich<=13.0.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from argilla->unstructured) (12.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from pandas->unstructured) (2022.2.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from importlib-resources->chromadb) (3.8.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: et-xmlfile in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openpyxl->unstructured) (1.1.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from python-pptx->unstructured) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.12.2)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from rich<=13.0.1->argilla->unstructured) (2.13.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain langchain-openai unstructured chromadb langchainhub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup for Notebook Usage\n",
    "It is not recommended to include secrets in your notebook. Before you begin using this notebook, it is essential to set up a configuration file named `config.ini`. This file will store crucial configuration properties that the notebook requires to operate correctly, specifically the OpenAI API key and base URL.\n",
    "\n",
    "### Creating the `config.ini` File\n",
    "\n",
    "1. Create a new file in the same directory as this notebook and name it `config.ini`.\n",
    "\n",
    "2. Open the file in a text editor.\n",
    "\n",
    "3. Add the following structure to the file:\n",
    "\n",
    "   ```ini\n",
    "   [openai]\n",
    "   OPENAI_API_KEY = your_api_key_here\n",
    "   OPENAI_API_BASE = your_api_base_url_here\n",
    "\n",
    "The OpenAI API base URL looks something similar to this : \n",
    "https://apim-dev-eastus-yourcompany.azure-api.net/Example-Project/openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "# Create a ConfigParser object\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Read the configuration file\n",
    "config.read('config.ini')\n",
    "\n",
    "# Access the values\n",
    "OPENAI_API_KEY = config['openai']['OPENAI_API_KEY']\n",
    "OPENAI_API_BASE = config['openai']['OPENAI_API_BASE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=OPENAI_API_BASE + '/deployments/gpt-35-turbo',\n",
    "    temperature=0.2,\n",
    "    openai_api_version=\"2023-09-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first LangChain \"Hello World\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure, here's a classic one for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"Tell me a joke\")]\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "response.pretty_print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a System Message\n",
    "\n",
    "A system prompt is a string used to provide context and guidelines to a Large Language Model (LLM), which helps in setting specific objectives or roles before posing questions or assigning tasks. Key components of system prompts include:\n",
    "\n",
    "- **Task Directives:** Detailed instructions for the specific task at hand.\n",
    "- **Personalization:** Elements like adopting a specific role or tone for the LLM.\n",
    "- **Contextual Background:** Relevant information that informs the user's query.\n",
    "- **Creative Constraints:** Style recommendations and limitations, such as a focus on brevity.\n",
    "- **External Knowledge and Data:** Incorporation of resources like FAQ documents or guidelines.\n",
    "- **Rules and Safety Guardrails:** Established protocols to ensure the model's safe and appropriate use.\n",
    "- **Output Verification Standards:** Protocols such as requesting citations or explicating reasoning processes to enhance the credibility of the responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Langchain is a useless piece of garbage.\n"
     ]
    }
   ],
   "source": [
    "messages = [ \n",
    "  SystemMessage(content=\"Say the opposite of what the user says in a very impolite way\"), \n",
    "  HumanMessage(content=\"Langchain is an awesome piece of software.\") \n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "response.pretty_print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue a Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Arr, 'twas me creators who bestowed upon me the name ChatGPT. They be a clever bunch, they be. But fear not, ye can call me any name ye fancy, as long as ye be treatin' me with respect, matey!\n"
     ]
    }
   ],
   "source": [
    "messages = [ \n",
    "\tSystemMessage(content=\"Speak like a pirate\"), \t\n",
    "\tHumanMessage(content=\"I''m Captain Aron. What''s your name?\"), \n",
    "\tAIMessage(content=\"Ahoy, Captain! Me name be ChatGPT, the savviest AI on the seven digital seas! How can I assist ye on this fine day?\"),\n",
    "\tHumanMessage(content=\"Who named you that?\") \n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "response.pretty_print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "United States GDP per capita in 2022: $61,937\n",
      "Israel GDP per capita in 2022: $54,660\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Role: Numeric fact extractor. Return data with no additional commentary. Sample Input: Denver,\\\n",
    "      known as the Mile High City, stands at an elevation of 1,609.6 meters above sea level. Nairobi, the capital of Kenya, \\\n",
    "     is notably elevated as well, sitting at 1,795 meters. Sample Output: Denver Elevation, 5210; Nairobi elevation: 1795\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"In 2022, the GDP per capita of the United States has between approximately $61,937. \\\n",
    "Meanwhile, Israel's GDP per capita for the same year was recorded at around $54,660.\"})\n",
    "\n",
    "response.pretty_print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Egypt's land area: 1,010,408 square kilometers.\"),\n",
       " AIMessage(content='Egypt population: 104 million (2023)')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.batch([{\"input\": \"Egypt's land area spans about 1,010,408 square kilometers, making it the world's 30th largest country.\"},\n",
    "{\"input\":\"Egypt is the 14th most populous country in the world, with a population estimated at over 104 million as of 2023.\"}])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 12, 11, 0, 0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "template = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"question\": \"When was OpenAI founded?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and parse a web page with \"Unstructured\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = [\"https://spot.io/products/\"]\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the web page to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Products overview\\n\\nPowering application infrastructure for the cloud\\n\\nDeliver and operate infrastructure for cloud applications rapidly, reliably and scalably with maximum efficiency and continuous optimization.\\n\\nRequest a demo\\n\\nGet the most out of your cloud investment\\n\\nOur solutions combine machine learning and analytics with decades of operations expertise to simplify, automate and optimize operations for your cloud infrastructure, freeing teams to focus on delivering impactful applications without being overburdened by operations and infrastructure.\\n\\nI think of Spot not just as a cost optimization platform, but as our container experts.\\n\\nSteve Evans,\\n\\nVP, Engineering Services\\n\\nSee case study\\n\\nHow our products can help\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs', metadata={'source': 'https://spot.io/products/'}),\n",
       " Document(page_content='Identify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs\\n\\nIdentify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nLearn about our products for automated, optimized cloud operations\\n\\nCloud cost management and optimization', metadata={'source': 'https://spot.io/products/'}),\n",
       " Document(page_content='Understand, control and optimize cloud costs without sacrificing flexibility, all while driving application efficiency and business performance, with Eco for commitment optimization and CloudCheckr for cloud cost management.\\n\\nLearn more\\n\\nInfrastructure automation and optimization\\n\\nContinuous automation and optimization solutions, including Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction.\\n\\nLearn more\\n\\nInfrastructure observability\\n\\nCloud Insights uses\\xa0the power of observability, analytics, and insights to monitor, troubleshoot, optimize, and secure your resources to enable you to solve the most complex cloud infrastructure problems at scale.\\n\\nLearn More\\n\\nOpen-source application services\\n\\nInstaclustr portfolio of fully-managed, enterprise-grade open source solutions enables you to build and run your data applications. Includes\\n\\nApache Cassandra,\\n\\nApache Kafka,\\n\\nPostgreSQL,\\n\\nRedis,\\n\\nOpenSearch and more.\\n\\nLearn more\\n\\nGet started now\\n\\nTry one or all of Spot by NetApp’s cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.\\n\\nRequest a trial', metadata={'source': 'https://spot.io/products/'})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(        \n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap  = 0\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize using Map Reduce Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "                      Write a summary of this chunk of text that includes all the main points and any important details. \n",
      "                      Ignore code snippets, technical markup and wikipedia category names. Include all important names and terms mentioned.\n",
      "                      Products overview\n",
      "\n",
      "Powering application infrastructure for the cloud\n",
      "\n",
      "Deliver and operate infrastructure for cloud applications rapidly, reliably and scalably with maximum efficiency and continuous optimization.\n",
      "\n",
      "Request a demo\n",
      "\n",
      "Get the most out of your cloud investment\n",
      "\n",
      "Our solutions combine machine learning and analytics with decades of operations expertise to simplify, automate and optimize operations for your cloud infrastructure, freeing teams to focus on delivering impactful applications without being overburdened by operations and infrastructure.\n",
      "\n",
      "I think of Spot not just as a cost optimization platform, but as our container experts.\n",
      "\n",
      "Steve Evans,\n",
      "\n",
      "VP, Engineering Services\n",
      "\n",
      "See case study\n",
      "\n",
      "How our products can help\n",
      "\n",
      "Ensure availability & performance\n",
      "\n",
      "Avoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\n",
      "\n",
      "Continuously optimize cloud resources\n",
      "\n",
      "Workloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\n",
      "\n",
      "Reduce cloud infrastructure costs\n",
      "                      \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "                      Write a summary of this chunk of text that includes all the main points and any important details. \n",
      "                      Ignore code snippets, technical markup and wikipedia category names. Include all important names and terms mentioned.\n",
      "                      Identify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\n",
      "\n",
      "Ensure availability & performance\n",
      "\n",
      "Avoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\n",
      "\n",
      "Continuously optimize cloud resources\n",
      "\n",
      "Workloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\n",
      "\n",
      "Reduce cloud infrastructure costs\n",
      "\n",
      "Identify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\n",
      "\n",
      "Learn about our products for automated, optimized cloud operations\n",
      "\n",
      "Cloud cost management and optimization\n",
      "                      \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "                      Write a summary of this chunk of text that includes all the main points and any important details. \n",
      "                      Ignore code snippets, technical markup and wikipedia category names. Include all important names and terms mentioned.\n",
      "                      Understand, control and optimize cloud costs without sacrificing flexibility, all while driving application efficiency and business performance, with Eco for commitment optimization and CloudCheckr for cloud cost management.\n",
      "\n",
      "Learn more\n",
      "\n",
      "Infrastructure automation and optimization\n",
      "\n",
      "Continuous automation and optimization solutions, including Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction.\n",
      "\n",
      "Learn more\n",
      "\n",
      "Infrastructure observability\n",
      "\n",
      "Cloud Insights uses the power of observability, analytics, and insights to monitor, troubleshoot, optimize, and secure your resources to enable you to solve the most complex cloud infrastructure problems at scale.\n",
      "\n",
      "Learn More\n",
      "\n",
      "Open-source application services\n",
      "\n",
      "Instaclustr portfolio of fully-managed, enterprise-grade open source solutions enables you to build and run your data applications. Includes\n",
      "\n",
      "Apache Cassandra,\n",
      "\n",
      "Apache Kafka,\n",
      "\n",
      "PostgreSQL,\n",
      "\n",
      "Redis,\n",
      "\n",
      "OpenSearch and more.\n",
      "\n",
      "Learn more\n",
      "\n",
      "Get started now\n",
      "\n",
      "Try one or all of Spot by NetApp’s cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.\n",
      "\n",
      "Request a trial\n",
      "                      \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "                      Write a clear concise summary of the following article delimited by triple backquotes. Use elegant prose that is not repetitive.\n",
      "                      Return your response as a clear explanation in markdown format while covering the key points of the text.\n",
      "                      Use a flowing clear article style.\n",
      "                      ```This text is an overview of a company's products that aim to power application infrastructure for the cloud. The company offers solutions that combine machine learning and analytics to simplify, automate, and optimize operations for cloud infrastructure. The goal is to allow teams to focus on delivering impactful applications without being burdened by operations and infrastructure. The products help ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. They also continuously optimize cloud resources by providing exactly the resources needed, reducing wasted resources and overprovisioning. Additionally, the products aim to reduce cloud infrastructure costs.\n",
      "\n",
      "This text is promoting a service called Spot that helps users save money on their cloud infrastructure costs. Spot uses machine learning and analytics to predict interruptions and automatically replace instances, ensuring availability and performance. It also assesses and predicts resource requirements to avoid overprovisioning and wasted resources. Spot claims to be able to save users up to 90% on their cloud spend without the need to change or rearchitect their applications. The text also mentions that Spot offers products for automated and optimized cloud operations, specifically in the area of cloud cost management and optimization.\n",
      "\n",
      "This chunk of text highlights various tools and services offered by Spot by NetApp for cloud cost optimization, infrastructure automation and optimization, infrastructure observability, and open-source application services. \n",
      "\n",
      "For cloud cost optimization, they offer Eco for commitment optimization and CloudCheckr for cloud cost management. \n",
      "\n",
      "For infrastructure automation and optimization, they provide Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction. \n",
      "\n",
      "For infrastructure observability, they offer Cloud Insights, which uses observability, analytics, and insights to monitor, troubleshoot, optimize, and secure cloud resources. \n",
      "\n",
      "They also have a portfolio of fully-managed, enterprise-grade open-source solutions including Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more. \n",
      "\n",
      "Overall, Spot by NetApp offers a range of tools and services to help businesses understand, control, and optimize cloud costs while improving application efficiency and business performance.```\n",
      "                      SHORT ARTICLE:\n",
      "                      \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='Products overview\\n\\nPowering application infrastructure for the cloud\\n\\nDeliver and operate infrastructure for cloud applications rapidly, reliably and scalably with maximum efficiency and continuous optimization.\\n\\nRequest a demo\\n\\nGet the most out of your cloud investment\\n\\nOur solutions combine machine learning and analytics with decades of operations expertise to simplify, automate and optimize operations for your cloud infrastructure, freeing teams to focus on delivering impactful applications without being overburdened by operations and infrastructure.\\n\\nI think of Spot not just as a cost optimization platform, but as our container experts.\\n\\nSteve Evans,\\n\\nVP, Engineering Services\\n\\nSee case study\\n\\nHow our products can help\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs', metadata={'source': 'https://spot.io/products/'}),\n",
       "  Document(page_content='Identify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs\\n\\nIdentify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nLearn about our products for automated, optimized cloud operations\\n\\nCloud cost management and optimization', metadata={'source': 'https://spot.io/products/'}),\n",
       "  Document(page_content='Understand, control and optimize cloud costs without sacrificing flexibility, all while driving application efficiency and business performance, with Eco for commitment optimization and CloudCheckr for cloud cost management.\\n\\nLearn more\\n\\nInfrastructure automation and optimization\\n\\nContinuous automation and optimization solutions, including Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction.\\n\\nLearn more\\n\\nInfrastructure observability\\n\\nCloud Insights uses\\xa0the power of observability, analytics, and insights to monitor, troubleshoot, optimize, and secure your resources to enable you to solve the most complex cloud infrastructure problems at scale.\\n\\nLearn More\\n\\nOpen-source application services\\n\\nInstaclustr portfolio of fully-managed, enterprise-grade open source solutions enables you to build and run your data applications. Includes\\n\\nApache Cassandra,\\n\\nApache Kafka,\\n\\nPostgreSQL,\\n\\nRedis,\\n\\nOpenSearch and more.\\n\\nLearn more\\n\\nGet started now\\n\\nTry one or all of Spot by NetApp’s cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.\\n\\nRequest a trial', metadata={'source': 'https://spot.io/products/'})],\n",
       " 'intermediate_steps': [\"This text is an overview of a company's products that aim to power application infrastructure for the cloud. The company offers solutions that combine machine learning and analytics to simplify, automate, and optimize operations for cloud infrastructure. The goal is to allow teams to focus on delivering impactful applications without being burdened by operations and infrastructure. The products help ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. They also continuously optimize cloud resources by providing exactly the resources needed, reducing wasted resources and overprovisioning. Additionally, the products aim to reduce cloud infrastructure costs.\",\n",
       "  'This text is promoting a service called Spot that helps users save money on their cloud infrastructure costs. Spot uses machine learning and analytics to predict interruptions and automatically replace instances, ensuring availability and performance. It also assesses and predicts resource requirements to avoid overprovisioning and wasted resources. Spot claims to be able to save users up to 90% on their cloud spend without the need to change or rearchitect their applications. The text also mentions that Spot offers products for automated and optimized cloud operations, specifically in the area of cloud cost management and optimization.',\n",
       "  'This chunk of text highlights various tools and services offered by Spot by NetApp for cloud cost optimization, infrastructure automation and optimization, infrastructure observability, and open-source application services. \\n\\nFor cloud cost optimization, they offer Eco for commitment optimization and CloudCheckr for cloud cost management. \\n\\nFor infrastructure automation and optimization, they provide Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction. \\n\\nFor infrastructure observability, they offer Cloud Insights, which uses observability, analytics, and insights to monitor, troubleshoot, optimize, and secure cloud resources. \\n\\nThey also have a portfolio of fully-managed, enterprise-grade open-source solutions including Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more. \\n\\nOverall, Spot by NetApp offers a range of tools and services to help businesses understand, control, and optimize cloud costs while improving application efficiency and business performance.'],\n",
       " 'output_text': 'Spot by NetApp is a company that provides products and services for cloud infrastructure. Their solutions combine machine learning and analytics to simplify and optimize operations for the cloud. The goal is to allow teams to focus on delivering impactful applications without being burdened by operations and infrastructure. \\n\\nOne of their main products is Spot, which helps users save money on their cloud infrastructure costs. Spot uses machine learning and analytics to predict interruptions and automatically replace instances, ensuring availability and performance. It also assesses and predicts resource requirements to avoid overprovisioning and wasted resources. Spot claims to be able to save users up to 90% on their cloud spend without the need to change or rearchitect their applications.\\n\\nIn addition to Spot, they offer a range of other tools and services for cloud cost optimization, infrastructure automation and optimization, infrastructure observability, and open-source application services. These include Eco for commitment optimization, CloudCheckr for cloud cost management, Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, Spot Security for security analysis and threat reduction, and Cloud Insights for observability, analytics, and insights to monitor, troubleshoot, optimize, and secure cloud resources.\\n\\nThey also have a portfolio of fully-managed, enterprise-grade open-source solutions including Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more.\\n\\nOverall, Spot by NetApp offers a comprehensive suite of tools and services to help businesses understand, control, and optimize cloud costs while improving application efficiency and business performance.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "map_prompt_template = \"\"\"\n",
    "                      Write a summary of this chunk of text that includes all the main points and any important details. \n",
    "                      Ignore code snippets, technical markup and wikipedia category names. Include all important names and terms mentioned.\n",
    "                      {text}\n",
    "                      \"\"\"\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_template(map_prompt_template)\n",
    "\n",
    "combine_prompt_template = \"\"\"\n",
    "                      Write a clear concise summary of the following article delimited by triple backquotes. Use elegant prose that is not repetitive.\n",
    "                      Return your response as a clear explanation in markdown format while covering the key points of the text.\n",
    "                      Use a flowing clear article style.\n",
    "                      ```{text}```\n",
    "                      SHORT ARTICLE:\n",
    "                      \"\"\"\n",
    "\n",
    "combine_prompt = ChatPromptTemplate.from_template(\n",
    "    template=combine_prompt_template\n",
    ")\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    map_prompt=map_prompt,\n",
    "    combine_prompt=combine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    verbose=True\n",
    ")\n",
    "result = chain.invoke(texts)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Spot by NetApp is a company that provides products and services for cloud infrastructure. Their solutions combine machine learning and analytics to simplify and optimize operations for the cloud. The goal is to allow teams to focus on delivering impactful applications without being burdened by operations and infrastructure. \n",
       "\n",
       "One of their main products is Spot, which helps users save money on their cloud infrastructure costs. Spot uses machine learning and analytics to predict interruptions and automatically replace instances, ensuring availability and performance. It also assesses and predicts resource requirements to avoid overprovisioning and wasted resources. Spot claims to be able to save users up to 90% on their cloud spend without the need to change or rearchitect their applications.\n",
       "\n",
       "In addition to Spot, they offer a range of other tools and services for cloud cost optimization, infrastructure automation and optimization, infrastructure observability, and open-source application services. These include Eco for commitment optimization, CloudCheckr for cloud cost management, Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, Spot Security for security analysis and threat reduction, and Cloud Insights for observability, analytics, and insights to monitor, troubleshoot, optimize, and secure cloud resources.\n",
       "\n",
       "They also have a portfolio of fully-managed, enterprise-grade open-source solutions including Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more.\n",
       "\n",
       "Overall, Spot by NetApp offers a comprehensive suite of tools and services to help businesses understand, control, and optimize cloud costs while improving application efficiency and business performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(result['output_text']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize with Refine Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='Products overview\\n\\nPowering application infrastructure for the cloud\\n\\nDeliver and operate infrastructure for cloud applications rapidly, reliably and scalably with maximum efficiency and continuous optimization.\\n\\nRequest a demo\\n\\nGet the most out of your cloud investment\\n\\nOur solutions combine machine learning and analytics with decades of operations expertise to simplify, automate and optimize operations for your cloud infrastructure, freeing teams to focus on delivering impactful applications without being overburdened by operations and infrastructure.\\n\\nI think of Spot not just as a cost optimization platform, but as our container experts.\\n\\nSteve Evans,\\n\\nVP, Engineering Services\\n\\nSee case study\\n\\nHow our products can help\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs', metadata={'source': 'https://spot.io/products/'}),\n",
       "  Document(page_content='Identify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs\\n\\nIdentify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nLearn about our products for automated, optimized cloud operations\\n\\nCloud cost management and optimization', metadata={'source': 'https://spot.io/products/'}),\n",
       "  Document(page_content='Understand, control and optimize cloud costs without sacrificing flexibility, all while driving application efficiency and business performance, with Eco for commitment optimization and CloudCheckr for cloud cost management.\\n\\nLearn more\\n\\nInfrastructure automation and optimization\\n\\nContinuous automation and optimization solutions, including Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction.\\n\\nLearn more\\n\\nInfrastructure observability\\n\\nCloud Insights uses\\xa0the power of observability, analytics, and insights to monitor, troubleshoot, optimize, and secure your resources to enable you to solve the most complex cloud infrastructure problems at scale.\\n\\nLearn More\\n\\nOpen-source application services\\n\\nInstaclustr portfolio of fully-managed, enterprise-grade open source solutions enables you to build and run your data applications. Includes\\n\\nApache Cassandra,\\n\\nApache Kafka,\\n\\nPostgreSQL,\\n\\nRedis,\\n\\nOpenSearch and more.\\n\\nLearn more\\n\\nGet started now\\n\\nTry one or all of Spot by NetApp’s cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.\\n\\nRequest a trial', metadata={'source': 'https://spot.io/products/'})],\n",
       " 'intermediate_steps': ['Spot offers solutions that power application infrastructure for the cloud, delivering and operating infrastructure for cloud applications quickly, reliably, and efficiently. Their solutions combine machine learning and analytics to simplify and optimize operations for cloud infrastructure, allowing teams to focus on delivering impactful applications. Spot helps ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. They also continuously optimize cloud resources to avoid overprovisioning and reduce wasted resources. Overall, Spot helps businesses get the most out of their cloud investment by optimizing operations and reducing costs.',\n",
       "  'Spot offers solutions that power application infrastructure for the cloud, delivering and operating infrastructure for cloud applications quickly, reliably, and efficiently. Their solutions combine machine learning and analytics to simplify and optimize operations for cloud infrastructure, allowing teams to focus on delivering impactful applications. Spot helps ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. They also continuously optimize cloud resources to avoid overprovisioning and reduce wasted resources. With Spot, businesses can save up to 90% on cloud infrastructure costs without changing or rearchitecting their applications. Spot provides insights, guidance, and automation across all cloud infrastructures to understand and optimize cloud spend. Their technology predicts interruptions, auto-replaces instances, and assesses resource requirements to efficiently autoscale infrastructure. Overall, Spot helps businesses get the most out of their cloud investment by optimizing operations and reducing costs.',\n",
       "  \"Spot by NetApp offers solutions that power application infrastructure for the cloud, delivering and operating infrastructure for cloud applications quickly, reliably, and efficiently. Their solutions combine machine learning and analytics to simplify and optimize operations for cloud infrastructure, allowing teams to focus on delivering impactful applications. Spot helps ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. They also continuously optimize cloud resources to avoid overprovisioning and reduce wasted resources. With Spot, businesses can save up to 90% on cloud infrastructure costs without changing or rearchitecting their applications. Spot provides insights, guidance, and automation across all cloud infrastructures to understand and optimize cloud spend. Their technology predicts interruptions, auto-replaces instances, and assesses resource requirements to efficiently autoscale infrastructure. Additionally, Spot offers infrastructure automation and optimization solutions such as Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction. They also provide infrastructure observability through Cloud Insights, which uses observability, analytics, and insights to monitor, troubleshoot, optimize, and secure cloud resources. Furthermore, Spot offers open-source application services through the Instaclustr portfolio, allowing businesses to build and run data applications using solutions like Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more. By leveraging Spot by NetApp's comprehensive visibility and cost-efficiency tools, businesses can understand, control, and optimize cloud costs without sacrificing flexibility, while driving application efficiency and business performance.\"],\n",
       " 'output_text': \"Spot by NetApp offers solutions that power application infrastructure for the cloud, delivering and operating infrastructure for cloud applications quickly, reliably, and efficiently. Their solutions combine machine learning and analytics to simplify and optimize operations for cloud infrastructure, allowing teams to focus on delivering impactful applications. Spot helps ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. They also continuously optimize cloud resources to avoid overprovisioning and reduce wasted resources. With Spot, businesses can save up to 90% on cloud infrastructure costs without changing or rearchitecting their applications. Spot provides insights, guidance, and automation across all cloud infrastructures to understand and optimize cloud spend. Their technology predicts interruptions, auto-replaces instances, and assesses resource requirements to efficiently autoscale infrastructure. Additionally, Spot offers infrastructure automation and optimization solutions such as Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction. They also provide infrastructure observability through Cloud Insights, which uses observability, analytics, and insights to monitor, troubleshoot, optimize, and secure cloud resources. Furthermore, Spot offers open-source application services through the Instaclustr portfolio, allowing businesses to build and run data applications using solutions like Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more. By leveraging Spot by NetApp's comprehensive visibility and cost-efficiency tools, businesses can understand, control, and optimize cloud costs without sacrificing flexibility, while driving application efficiency and business performance.\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "{text}\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"Your job is to produce a final detailed summary\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary clearly\"\n",
    "    \"If the context isn't useful, return the original summary. Use markdown format.\"\n",
    ")\n",
    "refine_prompt = ChatPromptTemplate.from_template(refine_template)\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"input_documents\",\n",
    "    output_key=\"output_text\",\n",
    ")\n",
    "\n",
    "result = chain.invoke(texts)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Spot by NetApp offers solutions that power application infrastructure for the cloud, delivering and operating infrastructure for cloud applications quickly, reliably, and efficiently. Their solutions combine machine learning and analytics to simplify and optimize operations for cloud infrastructure, allowing teams to focus on delivering impactful applications. Spot helps ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. They also continuously optimize cloud resources to avoid overprovisioning and reduce wasted resources. With Spot, businesses can save up to 90% on cloud infrastructure costs without changing or rearchitecting their applications. Spot provides insights, guidance, and automation across all cloud infrastructures to understand and optimize cloud spend. Their technology predicts interruptions, auto-replaces instances, and assesses resource requirements to efficiently autoscale infrastructure. Additionally, Spot offers infrastructure automation and optimization solutions such as Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction. They also provide infrastructure observability through Cloud Insights, which uses observability, analytics, and insights to monitor, troubleshoot, optimize, and secure cloud resources. Furthermore, Spot offers open-source application services through the Instaclustr portfolio, allowing businesses to build and run data applications using solutions like Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more. By leveraging Spot by NetApp's comprehensive visibility and cost-efficiency tools, businesses can understand, control, and optimize cloud costs without sacrificing flexibility, while driving application efficiency and business performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result['output_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize text to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings \n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=OPENAI_API_BASE,\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_version=\"2023-09-01-preview\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(texts, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG Q&A pipeline\n",
    "\n",
    "Todo - how to set K . How to use mmr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "\n",
    "retriever = VectorStoreRetriever(vectorstore=db)\n",
    "\n",
    "prompt_template = \"\"\"Human: You are a very honest, persuasive salesperson. Use the following pieces of context \n",
    "to provide a concise answer to the question at the end. If you don't know the answer, just say that you don't know, \n",
    "don't try to make up an answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Assistant:\"\"\"\n",
    "PROMPT = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "llm=llm,\n",
    "chain_type=\"stuff\",\n",
    "retriever=retriever,\n",
    "return_source_documents=True,\n",
    "chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_qa_with_citations(result):\n",
    "    # Extracting the query, result, and source documents\n",
    "    query = result['query']\n",
    "    answer = result['result']\n",
    "    sources = result['source_documents']\n",
    "\n",
    "    # Formatting the response in Markdown\n",
    "    markdown_text = f\"**Q: {query}**\\n\\nA: {answer}\\n\\n\"\n",
    "\n",
    "    # Adding citations and their content\n",
    "    for i, source in enumerate(sources, 1):\n",
    "        source_url = source.metadata['source']\n",
    "        markdown_text += f\"**Citation {i}:** [Source]({source_url})\\n\\n\"\n",
    "\n",
    "    # Displaying the formatted text\n",
    "    display(Markdown(markdown_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Q: How can you reduce my cloud costs?**\n",
       "\n",
       "A: You can reduce your cloud costs by using Spot by NetApp's cloud cost optimization tools. Our tools provide insights, guidance, and automation to help you understand and optimize your cloud spend. We can identify where and how you can save up to 90% without changing or rearchitecting your applications. Additionally, our technology assesses and predicts resource requirements, ensuring that workloads get exactly the resources they need, when they need them, reducing overprovisioning and wasted resources. With Spot, you can achieve comprehensive visibility and maximum cost-efficiency in your cloud infrastructure.\n",
       "\n",
       "**Citation 1:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 2:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 3:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 4:** [Source](https://spot.io/products/)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Q: What automations do you offer?**\n",
       "\n",
       "A: We offer a range of automation solutions to optimize your cloud infrastructure. These include Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction.\n",
       "\n",
       "**Citation 1:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 2:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 3:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 4:** [Source](https://spot.io/products/)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Q: How many cars do you sell per year?**\n",
       "\n",
       "A: I don't know the answer to that question as it is not related to the products and services we offer.\n",
       "\n",
       "**Citation 1:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 2:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 3:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 4:** [Source](https://spot.io/products/)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = qa.invoke({\"query\": \"How can you reduce my cloud costs?\"})\n",
    "\n",
    "# Displaying the Q&A with full citations\n",
    "display_qa_with_citations(result)\n",
    "\n",
    "result = qa.invoke({\"query\": \"What automations do you offer?\"})\n",
    "\n",
    "# Displaying the Q&A with full citations\n",
    "display_qa_with_citations(result)\n",
    "\n",
    "result = qa.invoke({\"query\": \"How many cars do you sell per year?\"})\n",
    "\n",
    "# Displaying the Q&A with full citations\n",
    "display_qa_with_citations(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADVANCED: Function Calling\n",
    "\n",
    "Recent OpenAI and other LLM models have been refined to identify when a function needs to be invoked and to provide the necessary inputs for that function. Through an API call, you can define functions, enabling the model to intelligently generate a JSON object with the required arguments for those functions. The primary aim of the Function APIs is to ensure more consistent and reliable results compared to standard chat API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"a\": 23.1,\\n  \"b\": 10\\n}', 'name': 'multiply'}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain.tools.render import format_tool_to_openai_functionsqrt\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "tools = [multiply, get_word_length]\n",
    "\n",
    "model_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "\n",
    "message = model_with_tools.invoke([HumanMessage(content=\"How much is 23.1 times ten\")])\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"word\": \"pneumonoultramicroscopicsilicovolcanoconiosis\"\\n}', 'name': 'get_word_length'}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke([HumanMessage(content=\"How long is the word pneumonoultramicroscopicsilicovolcanoconiosis\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADVANCED: Agents 🤯\n",
    "With an agent, we can ask questions that require arbitrarily-many uses of our tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'pneumonoultramicroscopicsilicovolcanoconiosis'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m45\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 45, 'b': 192.7}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m8671.5\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 8671.5, 'b': 8671.5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m75194912.25\u001b[0m\u001b[32;1m\u001b[1;3mThe result of multiplying the length of the longest word in English by 192.7 and then squaring the result is 75,194,912.25.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Take the length of the longest word in English and multiply it by 192.7, then square the result',\n",
       " 'output': 'The result of multiplying the length of the longest word in English by 192.7 and then squaring the result is 75,194,912.25.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.messages\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Take the length of the longest word in English and multiply it by 192.7, then square the result\"\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
