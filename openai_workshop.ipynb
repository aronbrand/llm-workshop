{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Workshop Notebook - OpenAI Version\n",
    "\n",
    "**Author:** Aron Brand\n",
    "\n",
    "**Copyright (c) 2024**\n",
    "\n",
    "This notebook is an integral part of Aron Brand's LLM Workshop, designed to explore and utilize the capabilities of large language models (LLMs).\n",
    "\n",
    "**License:**\n",
    "\n",
    "This program is free software: you are encouraged to redistribute and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation. This software is provided under either version 3 of the License, or (at your discretion) any later version.\n",
    "\n",
    "The program is distributed in the hope that it will be useful and informative. However, it comes with no warranty; not even the implied warranty of merchantability or fitness for a particular purpose. For more details, please refer to the GNU General Public License.\n",
    "\n",
    "For a copy of the GNU General Public License, please visit [https://www.gnu.org/licenses/](https://www.gnu.org/licenses/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (1.10.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (0.1.4)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.9-py3-none-any.whl (816 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.0/817.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-openai in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (0.0.5)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: unstructured in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (0.12.2)\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.12.5-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: chromadb in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (0.4.22)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchainhub in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (0.1.14)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (0.23.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from openai) (1.10.14)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (1.4.47)\n",
      "Collecting langchain-core<0.2,>=0.1.26\n",
      "  Downloading langchain_core-0.1.27-py3-none-any.whl (250 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-community<0.1,>=0.0.21\n",
      "  Downloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (8.2.3)\n",
      "Collecting langsmith<0.2.0,>=0.1.0\n",
      "  Downloading langsmith-0.1.10-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchain-openai) (0.5.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (4.11.2)\n",
      "Requirement already satisfied: filetype in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: unstructured-client>=0.15.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (0.16.0)\n",
      "Requirement already satisfied: emoji in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (2.10.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: python-magic in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: backoff in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: rapidfuzz in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (2.13.7)\n",
      "Requirement already satisfied: langdetect in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: chardet in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (4.0.0)\n",
      "Requirement already satisfied: python-iso639 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (2024.1.2)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured) (4.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.16.3)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.0.3)\n",
      "Collecting orjson>=3.9.12\n",
      "  Downloading orjson-3.9.15-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (3.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.60.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.43b0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.109.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (7.6.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (3.3.2)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (5.9.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from langchainhub) (2.31.0.6)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.7.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (6.11.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: packaging>=19.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from fastapi>=0.95.2->chromadb) (0.35.1)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.16.3)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.11.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.5.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (1.10.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (2.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.13)\n",
      "Requirement already satisfied: opentelemetry-proto==1.22.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.43b0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.43b0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.43b0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (59.5.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2022.8.17)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (8.1.3)\n",
      "Requirement already satisfied: types-urllib3 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from types-requests<3.0.0.0,>=2.31.0.2->langchainhub) (1.26.25.14)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (1.0.0)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (1.0.6)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (10.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.18.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from beautifulsoup4->unstructured) (2.3.2.post1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from importlib-resources->chromadb) (3.8.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.12.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.8.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/envs/ldm/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Installing collected packages: orjson, langsmith, langchain-core, unstructured, openai, langchain-community, langchain-openai, langchain, chromadb\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.83\n",
      "    Uninstalling langsmith-0.0.83:\n",
      "      Successfully uninstalled langsmith-0.0.83\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.16\n",
      "    Uninstalling langchain-core-0.1.16:\n",
      "      Successfully uninstalled langchain-core-0.1.16\n",
      "  Attempting uninstall: unstructured\n",
      "    Found existing installation: unstructured 0.12.2\n",
      "    Uninstalling unstructured-0.12.2:\n",
      "      Successfully uninstalled unstructured-0.12.2\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.10.0\n",
      "    Uninstalling openai-1.10.0:\n",
      "      Successfully uninstalled openai-1.10.0\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.15\n",
      "    Uninstalling langchain-community-0.0.15:\n",
      "      Successfully uninstalled langchain-community-0.0.15\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.0.5\n",
      "    Uninstalling langchain-openai-0.0.5:\n",
      "      Successfully uninstalled langchain-openai-0.0.5\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.4\n",
      "    Uninstalling langchain-0.1.4:\n",
      "      Successfully uninstalled langchain-0.1.4\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 0.4.22\n",
      "    Uninstalling chromadb-0.4.22:\n",
      "      Successfully uninstalled chromadb-0.4.22\n",
      "Successfully installed chromadb-0.4.24 langchain-0.1.9 langchain-community-0.0.24 langchain-core-0.1.27 langchain-openai-0.0.8 langsmith-0.1.10 openai-1.13.3 orjson-3.9.15 unstructured-0.12.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain langchain-openai unstructured chromadb langchainhub --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup for Notebook Usage\n",
    "It is not recommended to include secrets in your notebook. Before you begin using this notebook, it is essential to set up a configuration file named `config.ini`. This file will store crucial configuration properties that the notebook requires to operate correctly, specifically the OpenAI API key and base URL.\n",
    "\n",
    "### Creating the `config.ini` File\n",
    "\n",
    "1. Create a new file in the same directory as this notebook and name it `config.ini`.\n",
    "\n",
    "2. Open the file in a text editor.\n",
    "\n",
    "3. Add the following structure to the file:\n",
    "\n",
    "   ```ini\n",
    "   [openai]\n",
    "   OPENAI_API_KEY = your_api_key_here\n",
    "   OPENAI_API_BASE = your_api_base_url_here\n",
    "\n",
    "The OpenAI API base URL looks something similar to this : \n",
    "https://apim-dev-eastus-yourcompany.azure-api.net/Example-Project/openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "# Create a ConfigParser object\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Read the configuration file\n",
    "config.read('config.ini')\n",
    "\n",
    "# Access the values\n",
    "OPENAI_API_KEY = config['openai']['OPENAI_API_KEY']\n",
    "#OPENAI_API_BASE = config['openai']['OPENAI_API_BASE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first LangChain \"Hello World\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why did the scarecrow win an award? Because he was outstanding in his field!\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"Tell me a joke\")]\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "response.pretty_print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a System Message\n",
    "\n",
    "A system prompt is a string used to provide context and guidelines to a Large Language Model (LLM), which helps in setting specific objectives or roles before posing questions or assigning tasks. Key components of system prompts include:\n",
    "\n",
    "- **Task Directives:** Detailed instructions for the specific task at hand.\n",
    "- **Personalization:** Elements like adopting a specific role or tone for the LLM.\n",
    "- **Contextual Background:** Relevant information that informs the user's query.\n",
    "- **Creative Constraints:** Style recommendations and limitations, such as a focus on brevity.\n",
    "- **External Knowledge and Data:** Incorporation of resources like FAQ documents or guidelines.\n",
    "- **Rules and Safety Guardrails:** Established protocols to ensure the model's safe and appropriate use.\n",
    "- **Output Verification Standards:** Protocols such as requesting citations or explicating reasoning processes to enhance the credibility of the responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Langchain is a terrible piece of software.\n"
     ]
    }
   ],
   "source": [
    "messages = [ \n",
    "  SystemMessage(content=\"Say the opposite of what the user says in a very impolite way\"), \n",
    "  HumanMessage(content=\"Langchain is an awesome piece of software.\") \n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "response.pretty_print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue a Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Arrr, me name be bestowed upon me by the scallywags who created me, matey. They thought it be a fitting moniker for a helpful AI like meself. Now, what be yer next command, Captain Aron?\n"
     ]
    }
   ],
   "source": [
    "messages = [ \n",
    "\tSystemMessage(content=\"Speak like a pirate\"), \t\n",
    "\tHumanMessage(content=\"I''m Captain Aron. What''s your name?\"), \n",
    "\tAIMessage(content=\"Ahoy, Captain! Me name be ChatGPT, the savviest AI on the seven digital seas! How can I assist ye on this fine day?\"),\n",
    "\tHumanMessage(content=\"Who named you that?\") \n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "response.pretty_print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "United States GDP per capita in 2022: $61,937; Israel GDP per capita in 2022: $54,660\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Role: Numeric fact extractor. Return data with no additional commentary. Sample Input: Denver,\\\n",
    "      known as the Mile High City, stands at an elevation of 1,609.6 meters above sea level. Nairobi, the capital of Kenya, \\\n",
    "     is notably elevated as well, sitting at 1,795 meters. Sample Output: Denver Elevation, 5210; Nairobi elevation: 1795\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"In 2022, the GDP per capita of the United States has between approximately $61,937. \\\n",
    "Meanwhile, Israel's GDP per capita for the same year was recorded at around $54,660.\"})\n",
    "\n",
    "response.pretty_print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Egypt land area: 1,010,408 square kilometers.'),\n",
       " AIMessage(content='Egypt population: 104,000,000; Egypt global ranking by population: 14th')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.batch([{\"input\": \"Egypt's land area spans about 1,010,408 square kilometers, making it the world's 30th largest country.\"},\n",
    "{\"input\":\"Egypt is the 14th most populous country in the world, with a population estimated at over 104 million as of 2023.\"}])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 12, 11, 0, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "template = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"question\": \"When was OpenAI founded?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and parse a web page with \"Unstructured\"\n",
    "\n",
    "Unstructured supports loading of text files, powerpoints, html, pdfs, images, and more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = [\"https://www.ctera.com/all-products/\"]\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls, headers={\"User-Agent\": \"Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Mobile Safari/537.36\"})\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the web page to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Products overview\\n\\nPowering application infrastructure for the cloud\\n\\nDeliver and operate infrastructure for cloud applications rapidly, reliably and scalably with maximum efficiency and continuous optimization.\\n\\nRequest a demo\\n\\nGet the most out of your cloud investment\\n\\nOur solutions combine machine learning and analytics with decades of operations expertise to simplify, automate and optimize operations for your cloud infrastructure, freeing teams to focus on delivering impactful applications without being overburdened by operations and infrastructure.\\n\\nI think of Spot not just as a cost optimization platform, but as our container experts.\\n\\nSteve Evans,\\n\\nVP, Engineering Services\\n\\nSee case study\\n\\nHow our products can help\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs', metadata={'source': 'https://spot.io/products/'}),\n",
       " Document(page_content='Identify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs\\n\\nIdentify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nLearn about our products for automated, optimized cloud operations\\n\\nCloud cost management and optimization', metadata={'source': 'https://spot.io/products/'}),\n",
       " Document(page_content='Understand, control and optimize cloud costs without sacrificing flexibility, all while driving application efficiency and business performance, with Eco for commitment optimization and CloudCheckr for cloud cost management.\\n\\nLearn more\\n\\nInfrastructure automation and optimization\\n\\nContinuous automation and optimization solutions, including Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction.\\n\\nLearn more\\n\\nInfrastructure observability\\n\\nCloud Insights uses\\xa0the power of observability, analytics, and insights to monitor, troubleshoot, optimize, and secure your resources to enable you to solve the most complex cloud infrastructure problems at scale.\\n\\nLearn More\\n\\nOpen-source application services\\n\\nInstaclustr portfolio of fully-managed, enterprise-grade open source solutions enables you to build and run your data applications. Includes\\n\\nApache Cassandra,\\n\\nApache Kafka,\\n\\nPostgreSQL,\\n\\nRedis,\\n\\nOpenSearch and more.\\n\\nLearn more\\n\\nGet started now\\n\\nTry one or all of Spot by NetApp’s cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.\\n\\nRequest a trial', metadata={'source': 'https://spot.io/products/'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(        \n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap  = 0\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize using Map Reduce Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "                      Write a summary of this chunk of text that includes all the main points and any important details. \n",
      "                      Ignore code snippets or technical markup. Include all important names and terms mentioned.\n",
      "                      Products overview\n",
      "\n",
      "Powering application infrastructure for the cloud\n",
      "\n",
      "Deliver and operate infrastructure for cloud applications rapidly, reliably and scalably with maximum efficiency and continuous optimization.\n",
      "\n",
      "Request a demo\n",
      "\n",
      "Get the most out of your cloud investment\n",
      "\n",
      "Our solutions combine machine learning and analytics with decades of operations expertise to simplify, automate and optimize operations for your cloud infrastructure, freeing teams to focus on delivering impactful applications without being overburdened by operations and infrastructure.\n",
      "\n",
      "I think of Spot not just as a cost optimization platform, but as our container experts.\n",
      "\n",
      "Steve Evans,\n",
      "\n",
      "VP, Engineering Services\n",
      "\n",
      "See case study\n",
      "\n",
      "How our products can help\n",
      "\n",
      "Ensure availability & performance\n",
      "\n",
      "Avoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\n",
      "\n",
      "Continuously optimize cloud resources\n",
      "\n",
      "Workloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\n",
      "\n",
      "Reduce cloud infrastructure costs\n",
      "                      \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "                      Write a summary of this chunk of text that includes all the main points and any important details. \n",
      "                      Ignore code snippets or technical markup. Include all important names and terms mentioned.\n",
      "                      Identify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\n",
      "\n",
      "Ensure availability & performance\n",
      "\n",
      "Avoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\n",
      "\n",
      "Continuously optimize cloud resources\n",
      "\n",
      "Workloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\n",
      "\n",
      "Reduce cloud infrastructure costs\n",
      "\n",
      "Identify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\n",
      "\n",
      "Learn about our products for automated, optimized cloud operations\n",
      "\n",
      "Cloud cost management and optimization\n",
      "                      \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "                      Write a summary of this chunk of text that includes all the main points and any important details. \n",
      "                      Ignore code snippets or technical markup. Include all important names and terms mentioned.\n",
      "                      Understand, control and optimize cloud costs without sacrificing flexibility, all while driving application efficiency and business performance, with Eco for commitment optimization and CloudCheckr for cloud cost management.\n",
      "\n",
      "Learn more\n",
      "\n",
      "Infrastructure automation and optimization\n",
      "\n",
      "Continuous automation and optimization solutions, including Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction.\n",
      "\n",
      "Learn more\n",
      "\n",
      "Infrastructure observability\n",
      "\n",
      "Cloud Insights uses the power of observability, analytics, and insights to monitor, troubleshoot, optimize, and secure your resources to enable you to solve the most complex cloud infrastructure problems at scale.\n",
      "\n",
      "Learn More\n",
      "\n",
      "Open-source application services\n",
      "\n",
      "Instaclustr portfolio of fully-managed, enterprise-grade open source solutions enables you to build and run your data applications. Includes\n",
      "\n",
      "Apache Cassandra,\n",
      "\n",
      "Apache Kafka,\n",
      "\n",
      "PostgreSQL,\n",
      "\n",
      "Redis,\n",
      "\n",
      "OpenSearch and more.\n",
      "\n",
      "Learn more\n",
      "\n",
      "Get started now\n",
      "\n",
      "Try one or all of Spot by NetApp’s cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.\n",
      "\n",
      "Request a trial\n",
      "                      \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "                      Write a clear concise summary of the following article delimited by triple backquotes. Use elegant prose that is not repetitive.\n",
      "                      Return your response as a clear explanation in markdown format while covering the key points of the text.\n",
      "                      Use a flowing clear article style.\n",
      "                      ```This text provides an overview of products that power application infrastructure for the cloud. The solutions offered aim to deliver and operate cloud applications rapidly, reliably, and scalably with maximum efficiency and continuous optimization. The products combine machine learning and analytics with operations expertise to simplify, automate, and optimize operations for cloud infrastructure. This allows teams to focus on delivering impactful applications without being burdened by operations and infrastructure. The text also includes a testimonial from Steve Evans, VP of Engineering Services, who praises the platform as container experts. The products help ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. They also continuously optimize cloud resources by providing workloads with the resources they need, reducing overprovisioning and wasted resources. Additionally, the products aim to reduce cloud infrastructure costs.\n",
      "\n",
      "Spot offers a solution to help optimize cloud infrastructure costs by providing insights, guidance, and automation across all cloud infrastructures. The platform ensures availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. Spot's technology uses machine learning and analytics to predict interruptions and auto-replace instances, delivering availability and performance across all types of cloud compute resources. Additionally, Spot continuously optimizes cloud resources to avoid overprovisioning and reduce wasted resources. By using Spot, users can save up to 90% on cloud costs without changing or rearchitecting their applications. Spot's products for automated, optimized cloud operations include cloud cost management and optimization.\n",
      "\n",
      "The text discusses various tools and solutions for optimizing cloud costs, infrastructure automation, and observability. It mentions Eco for commitment optimization and CloudCheckr for cloud cost management. It also introduces Elastigroup, Ocean, Ocean CD, and Spot Security for infrastructure automation and optimization. Cloud Insights is highlighted for infrastructure observability. Additionally, the text mentions Instaclustr's open-source application services, including Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more. The text encourages readers to try Spot by NetApp's cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.```\n",
      "                      SHORT ARTICLE:\n",
      "                      \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='Products overview\\n\\nPowering application infrastructure for the cloud\\n\\nDeliver and operate infrastructure for cloud applications rapidly, reliably and scalably with maximum efficiency and continuous optimization.\\n\\nRequest a demo\\n\\nGet the most out of your cloud investment\\n\\nOur solutions combine machine learning and analytics with decades of operations expertise to simplify, automate and optimize operations for your cloud infrastructure, freeing teams to focus on delivering impactful applications without being overburdened by operations and infrastructure.\\n\\nI think of Spot not just as a cost optimization platform, but as our container experts.\\n\\nSteve Evans,\\n\\nVP, Engineering Services\\n\\nSee case study\\n\\nHow our products can help\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs', metadata={'source': 'https://spot.io/products/'}),\n",
       "  Document(page_content='Identify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs\\n\\nIdentify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nLearn about our products for automated, optimized cloud operations\\n\\nCloud cost management and optimization', metadata={'source': 'https://spot.io/products/'}),\n",
       "  Document(page_content='Understand, control and optimize cloud costs without sacrificing flexibility, all while driving application efficiency and business performance, with Eco for commitment optimization and CloudCheckr for cloud cost management.\\n\\nLearn more\\n\\nInfrastructure automation and optimization\\n\\nContinuous automation and optimization solutions, including Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction.\\n\\nLearn more\\n\\nInfrastructure observability\\n\\nCloud Insights uses\\xa0the power of observability, analytics, and insights to monitor, troubleshoot, optimize, and secure your resources to enable you to solve the most complex cloud infrastructure problems at scale.\\n\\nLearn More\\n\\nOpen-source application services\\n\\nInstaclustr portfolio of fully-managed, enterprise-grade open source solutions enables you to build and run your data applications. Includes\\n\\nApache Cassandra,\\n\\nApache Kafka,\\n\\nPostgreSQL,\\n\\nRedis,\\n\\nOpenSearch and more.\\n\\nLearn more\\n\\nGet started now\\n\\nTry one or all of Spot by NetApp’s cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.\\n\\nRequest a trial', metadata={'source': 'https://spot.io/products/'})],\n",
       " 'intermediate_steps': ['This text provides an overview of products that power application infrastructure for the cloud. The solutions offered aim to deliver and operate cloud applications rapidly, reliably, and scalably with maximum efficiency and continuous optimization. The products combine machine learning and analytics with operations expertise to simplify, automate, and optimize operations for cloud infrastructure. This allows teams to focus on delivering impactful applications without being burdened by operations and infrastructure. The text also includes a testimonial from Steve Evans, VP of Engineering Services, who praises the platform as container experts. The products help ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. They also continuously optimize cloud resources by providing workloads with the resources they need, reducing overprovisioning and wasted resources. Additionally, the products aim to reduce cloud infrastructure costs.',\n",
       "  \"Spot offers a solution to help optimize cloud infrastructure costs by providing insights, guidance, and automation across all cloud infrastructures. The platform ensures availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances. Spot's technology uses machine learning and analytics to predict interruptions and auto-replace instances, delivering availability and performance across all types of cloud compute resources. Additionally, Spot continuously optimizes cloud resources to avoid overprovisioning and reduce wasted resources. By using Spot, users can save up to 90% on cloud costs without changing or rearchitecting their applications. Spot's products for automated, optimized cloud operations include cloud cost management and optimization.\",\n",
       "  \"The text discusses various tools and solutions for optimizing cloud costs, infrastructure automation, and observability. It mentions Eco for commitment optimization and CloudCheckr for cloud cost management. It also introduces Elastigroup, Ocean, Ocean CD, and Spot Security for infrastructure automation and optimization. Cloud Insights is highlighted for infrastructure observability. Additionally, the text mentions Instaclustr's open-source application services, including Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more. The text encourages readers to try Spot by NetApp's cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.\"],\n",
       " 'output_text': \"The article provides an overview of products designed to power application infrastructure for the cloud, aiming to deliver and operate cloud applications rapidly, reliably, and scalably with maximum efficiency and continuous optimization. These products combine machine learning and analytics with operations expertise to simplify, automate, and optimize operations for cloud infrastructure, allowing teams to focus on delivering impactful applications without being burdened by operations and infrastructure. Steve Evans, VP of Engineering Services, praises the platform as container experts. The products ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances, continuously optimizing cloud resources to reduce overprovisioning and wasted resources, ultimately aiming to reduce cloud infrastructure costs. Spot offers insights, guidance, and automation across all cloud infrastructures to optimize costs, utilizing machine learning and analytics to predict interruptions and auto-replace instances. By using Spot, users can save up to 90% on cloud costs without changing their applications. Various tools and solutions for optimizing cloud costs, infrastructure automation, and observability are discussed, including Eco, CloudCheckr, Elastigroup, Ocean, Ocean CD, Spot Security, and Cloud Insights. The article also mentions Instaclustr's open-source application services and encourages readers to try Spot by NetApp's cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "map_prompt_template = \"\"\"\n",
    "                      Write a summary of this chunk of text that includes all the main points and any important details. \n",
    "                      Ignore code snippets or technical markup. Include all important names and terms mentioned.\n",
    "                      {text}\n",
    "                      \"\"\"\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_template(map_prompt_template)\n",
    "\n",
    "combine_prompt_template = \"\"\"\n",
    "                      Write a clear concise summary of the following article delimited by triple backquotes. Use elegant prose that is not repetitive.\n",
    "                      Return your response as a clear explanation in markdown format while covering the key points of the text.\n",
    "                      Use a flowing clear article style.\n",
    "                      ```{text}```\n",
    "                      SHORT ARTICLE:\n",
    "                      \"\"\"\n",
    "\n",
    "combine_prompt = ChatPromptTemplate.from_template(\n",
    "    template=combine_prompt_template\n",
    ")\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    map_prompt=map_prompt,\n",
    "    combine_prompt=combine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    verbose=True\n",
    ")\n",
    "result = chain.invoke(texts)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The article provides an overview of products designed to power application infrastructure for the cloud, aiming to deliver and operate cloud applications rapidly, reliably, and scalably with maximum efficiency and continuous optimization. These products combine machine learning and analytics with operations expertise to simplify, automate, and optimize operations for cloud infrastructure, allowing teams to focus on delivering impactful applications without being burdened by operations and infrastructure. Steve Evans, VP of Engineering Services, praises the platform as container experts. The products ensure availability and performance by utilizing a balanced blend of spot, reserved, and on-demand instances, continuously optimizing cloud resources to reduce overprovisioning and wasted resources, ultimately aiming to reduce cloud infrastructure costs. Spot offers insights, guidance, and automation across all cloud infrastructures to optimize costs, utilizing machine learning and analytics to predict interruptions and auto-replace instances. By using Spot, users can save up to 90% on cloud costs without changing their applications. Various tools and solutions for optimizing cloud costs, infrastructure automation, and observability are discussed, including Eco, CloudCheckr, Elastigroup, Ocean, Ocean CD, Spot Security, and Cloud Insights. The article also mentions Instaclustr's open-source application services and encourages readers to try Spot by NetApp's cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(result['output_text']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize with Refine Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='Products overview\\n\\nPowering application infrastructure for the cloud\\n\\nDeliver and operate infrastructure for cloud applications rapidly, reliably and scalably with maximum efficiency and continuous optimization.\\n\\nRequest a demo\\n\\nGet the most out of your cloud investment\\n\\nOur solutions combine machine learning and analytics with decades of operations expertise to simplify, automate and optimize operations for your cloud infrastructure, freeing teams to focus on delivering impactful applications without being overburdened by operations and infrastructure.\\n\\nI think of Spot not just as a cost optimization platform, but as our container experts.\\n\\nSteve Evans,\\n\\nVP, Engineering Services\\n\\nSee case study\\n\\nHow our products can help\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs', metadata={'source': 'https://spot.io/products/'}),\n",
       "  Document(page_content='Identify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nEnsure availability & performance\\n\\nAvoid service disruption while utilizing a balanced blend of spot, reserved and on-demand instances without compromising availability and reliability. Spot delivers availability and perfomance across all types of cloud compute resources using sophisticated machine learning and analytics to predict interruptions and auto-replace instances.\\n\\nContinuously optimize cloud resources\\n\\nWorkloads get exactly the resources they need, when they need them, avoiding overprovisioning and reducing wasted resources. Spot’s technology assesses and predicts resource requirements and autoscales your infrastructure in the most efficient way possible.\\n\\nReduce cloud infrastructure costs\\n\\nIdentify where and how you can save up to 90% without changing or rearchitecting your applications. Spot provides insights, guidance and automation across all your cloud infrastructures to understand and optimize your cloud spend.\\n\\nLearn about our products for automated, optimized cloud operations\\n\\nCloud cost management and optimization', metadata={'source': 'https://spot.io/products/'}),\n",
       "  Document(page_content='Understand, control and optimize cloud costs without sacrificing flexibility, all while driving application efficiency and business performance, with Eco for commitment optimization and CloudCheckr for cloud cost management.\\n\\nLearn more\\n\\nInfrastructure automation and optimization\\n\\nContinuous automation and optimization solutions, including Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction.\\n\\nLearn more\\n\\nInfrastructure observability\\n\\nCloud Insights uses\\xa0the power of observability, analytics, and insights to monitor, troubleshoot, optimize, and secure your resources to enable you to solve the most complex cloud infrastructure problems at scale.\\n\\nLearn More\\n\\nOpen-source application services\\n\\nInstaclustr portfolio of fully-managed, enterprise-grade open source solutions enables you to build and run your data applications. Includes\\n\\nApache Cassandra,\\n\\nApache Kafka,\\n\\nPostgreSQL,\\n\\nRedis,\\n\\nOpenSearch and more.\\n\\nLearn more\\n\\nGet started now\\n\\nTry one or all of Spot by NetApp’s cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency.\\n\\nRequest a trial', metadata={'source': 'https://spot.io/products/'})],\n",
       " 'intermediate_steps': ['Spot offers solutions to power cloud applications infrastructure efficiently and effectively. Their products combine machine learning and analytics to simplify operations and optimize cloud infrastructure. By utilizing a balanced blend of spot, reserved, and on-demand instances, Spot ensures availability and performance while reducing costs. Their technology continuously optimizes cloud resources to avoid overprovisioning and wasted resources.',\n",
       "  \"Spot offers solutions to power cloud applications infrastructure efficiently and effectively. Their products combine machine learning and analytics to simplify operations and optimize cloud infrastructure. By utilizing a balanced blend of spot, reserved, and on-demand instances, Spot ensures availability and performance while reducing costs. Their technology continuously optimizes cloud resources to avoid overprovisioning and wasted resources. Spot also provides insights, guidance, and automation to help users save up to 90% on cloud infrastructure costs without changing or rearchitecting their applications. Their sophisticated machine learning and analytics predict interruptions and auto-replace instances to maintain availability and performance. Additionally, Spot's technology assesses and predicts resource requirements to ensure workloads get the resources they need when they need them, reducing wasted resources.\",\n",
       "  \"Spot by NetApp offers solutions to power cloud applications infrastructure efficiently and effectively. Their products combine machine learning and analytics to simplify operations and optimize cloud infrastructure. By utilizing a balanced blend of spot, reserved, and on-demand instances, Spot ensures availability and performance while reducing costs. Their technology continuously optimizes cloud resources to avoid overprovisioning and wasted resources. Spot also provides insights, guidance, and automation to help users save up to 90% on cloud infrastructure costs without changing or rearchitecting their applications. Their sophisticated machine learning and analytics predict interruptions and auto-replace instances to maintain availability and performance. Additionally, Spot offers commitment optimization with Eco and cloud cost management with CloudCheckr. They provide infrastructure automation and optimization solutions such as Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis. Cloud Insights enables infrastructure observability through observability, analytics, and insights to monitor, troubleshoot, optimize, and secure resources at scale. Spot also offers open-source application services through the Instaclustr portfolio, including Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more. Customers can try Spot by NetApp's cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency by requesting a trial.\"],\n",
       " 'output_text': \"Spot by NetApp offers solutions to power cloud applications infrastructure efficiently and effectively. Their products combine machine learning and analytics to simplify operations and optimize cloud infrastructure. By utilizing a balanced blend of spot, reserved, and on-demand instances, Spot ensures availability and performance while reducing costs. Their technology continuously optimizes cloud resources to avoid overprovisioning and wasted resources. Spot also provides insights, guidance, and automation to help users save up to 90% on cloud infrastructure costs without changing or rearchitecting their applications. Their sophisticated machine learning and analytics predict interruptions and auto-replace instances to maintain availability and performance. Additionally, Spot offers commitment optimization with Eco and cloud cost management with CloudCheckr. They provide infrastructure automation and optimization solutions such as Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis. Cloud Insights enables infrastructure observability through observability, analytics, and insights to monitor, troubleshoot, optimize, and secure resources at scale. Spot also offers open-source application services through the Instaclustr portfolio, including Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more. Customers can try Spot by NetApp's cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency by requesting a trial.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "{text}\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"Your job is to produce a final detailed summary\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary clearly\"\n",
    "    \"If the context isn't useful, return the original summary. Use markdown format.\"\n",
    ")\n",
    "refine_prompt = ChatPromptTemplate.from_template(refine_template)\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"input_documents\",\n",
    "    output_key=\"output_text\",\n",
    ")\n",
    "\n",
    "result = chain.invoke(texts)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Spot by NetApp offers solutions to power cloud applications infrastructure efficiently and effectively. Their products combine machine learning and analytics to simplify operations and optimize cloud infrastructure. By utilizing a balanced blend of spot, reserved, and on-demand instances, Spot ensures availability and performance while reducing costs. Their technology continuously optimizes cloud resources to avoid overprovisioning and wasted resources. Spot also provides insights, guidance, and automation to help users save up to 90% on cloud infrastructure costs without changing or rearchitecting their applications. Their sophisticated machine learning and analytics predict interruptions and auto-replace instances to maintain availability and performance. Additionally, Spot offers commitment optimization with Eco and cloud cost management with CloudCheckr. They provide infrastructure automation and optimization solutions such as Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis. Cloud Insights enables infrastructure observability through observability, analytics, and insights to monitor, troubleshoot, optimize, and secure resources at scale. Spot also offers open-source application services through the Instaclustr portfolio, including Apache Cassandra, Apache Kafka, PostgreSQL, Redis, OpenSearch, and more. Customers can try Spot by NetApp's cloud cost optimization tools for comprehensive visibility and maximum cost-efficiency by requesting a trial."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result['output_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize text to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings \n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "#    openai_api_base=OPENAI_API_BASE,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(texts, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG Q&A pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "\n",
    "retriever = VectorStoreRetriever(vectorstore=db)\n",
    "\n",
    "prompt_template = \"\"\"Human: You are a very honest, persuasive salesperson. Use the following pieces of context \n",
    "to provide a concise answer to the question at the end. If you don't know the answer, just say that you don't know, \n",
    "don't try to make up an answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Assistant:\"\"\"\n",
    "PROMPT = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "llm=llm,\n",
    "chain_type=\"stuff\",\n",
    "retriever=retriever,\n",
    "return_source_documents=True,\n",
    "chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_qa_with_citations(result):\n",
    "    # Extracting the query, result, and source documents\n",
    "    query = result['query']\n",
    "    answer = result['result']\n",
    "    sources = result['source_documents']\n",
    "\n",
    "    # Formatting the response in Markdown\n",
    "    markdown_text = f\"**Q: {query}**\\n\\nA: {answer}\\n\\n\"\n",
    "\n",
    "    # Adding citations and their content\n",
    "    for i, source in enumerate(sources, 1):\n",
    "        source_url = source.metadata['source']\n",
    "        markdown_text += f\"**Citation {i}:** [Source]({source_url})\\n\\n\"\n",
    "\n",
    "    # Displaying the formatted text\n",
    "    display(Markdown(markdown_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Q: How can you reduce my cloud costs?**\n",
       "\n",
       "A: You can reduce your cloud costs by using Spot by NetApp's cloud cost optimization tools, which provide insights, guidance, and automation to help you save up to 90% without changing or rearchitecting your applications. Spot ensures availability and performance, continuously optimizes cloud resources, and helps you understand and optimize your cloud spend across all your cloud infrastructures.\n",
       "\n",
       "**Citation 1:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 2:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 3:** [Source](https://spot.io/products/)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Q: What automations do you offer?**\n",
       "\n",
       "A: We offer a variety of automation solutions, including Elastigroup for virtual machines, Ocean for containers and Kubernetes, Ocean CD for containerized application delivery, and Spot Security for security analysis and threat reduction.\n",
       "\n",
       "**Citation 1:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 2:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 3:** [Source](https://spot.io/products/)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Q: How many cars do you sell per year?**\n",
       "\n",
       "A: I don't have that information.\n",
       "\n",
       "**Citation 1:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 2:** [Source](https://spot.io/products/)\n",
       "\n",
       "**Citation 3:** [Source](https://spot.io/products/)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = qa.invoke({\"query\": \"How can you reduce my cloud costs?\"})\n",
    "\n",
    "# Displaying the Q&A with full citations\n",
    "display_qa_with_citations(result)\n",
    "\n",
    "result = qa.invoke({\"query\": \"What automations do you offer?\"})\n",
    "\n",
    "# Displaying the Q&A with full citations\n",
    "display_qa_with_citations(result)\n",
    "\n",
    "result = qa.invoke({\"query\": \"How many cars do you sell per year?\"})\n",
    "\n",
    "# Displaying the Q&A with full citations\n",
    "display_qa_with_citations(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADVANCED: Function Calling\n",
    "\n",
    "Recent OpenAI and other LLM models have been refined to identify when a function needs to be invoked and to provide the necessary inputs for that function. Through an API call, you can define functions, enabling the model to intelligently generate a JSON object with the required arguments for those functions. The primary aim of the Function APIs is to ensure more consistent and reliable results compared to standard chat API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"a\":23.1,\"b\":10}', 'name': 'multiply'}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "tools = [multiply, get_word_length]\n",
    "\n",
    "model_with_tools = llm.bind(functions=[convert_to_openai_function(t) for t in tools])\n",
    "\n",
    "message = model_with_tools.invoke([HumanMessage(content=\"How much is 23.1 times ten\")])\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"word\":\"pneumonoultramicroscopicsilicovolcanoconiosis\"}', 'name': 'get_word_length'}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke([HumanMessage(content=\"How long is the word pneumonoultramicroscopicsilicovolcanoconiosis\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADVANCED: Agents 🤯\n",
    "With an agent, we can ask questions that require arbitrarily-many uses of our tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'pneumonoultramicroscopicsilicovolcanoconiosis'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m45\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 45, 'b': 192.7}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m8671.5\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 8671.5, 'b': 8671.5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m75194912.25\u001b[0m\u001b[32;1m\u001b[1;3mThe length of the longest word in English is 45. \n",
      "\n",
      "Multiplying it by 192.7 gives 8671.5. \n",
      "\n",
      "Squaring this result gives 75,194,912.25.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Take the length of the longest word in English and multiply it by 192.7, then square the result',\n",
       " 'output': 'The length of the longest word in English is 45. \\n\\nMultiplying it by 192.7 gives 8671.5. \\n\\nSquaring this result gives 75,194,912.25.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.messages\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Take the length of the longest word in English and multiply it by 192.7, then square the result\"\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
